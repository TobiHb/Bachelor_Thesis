{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35a11466-ea69-4a36-9e63-319c1ed02492",
   "metadata": {},
   "source": [
    "# 04_Model_Comparison_Eval.ipynb\n",
    "### Purpose: Evaluate and compare BERT vs. TAPT-BERT on the FiNER-139 test set\n",
    "<hr style=\"height:3px; width:100%; background-color:black; border:none; margin:auto;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fa5efa-f07a-4769-9d2d-7a22aa87864b",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1cc8fe7-1cd7-4d0c-9fb7-bac109155d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import BertTokenizerFast, BertForTokenClassification\n",
    "from transformers import DataCollatorForTokenClassification, Trainer, TrainingArguments\n",
    "import evaluate\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f9f349-57ca-4a4a-9b61-2f2253728bfb",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px; width:100%; background-color:black; border:none; margin:auto;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4900a793-3f67-4822-8984-20a68eff687a",
   "metadata": {},
   "source": [
    "## 2. Load the FiNER-139 Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8059c6ac-a49b-431f-bd37-a6ff165f8b84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e6b26ef57814273b45346bb7bcc39a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ff4df4eca554c79b311e24f44dbbcd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25847a4272d14c31ba7baa8f9cd48cad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'tokens', 'ner_tags_str_mapped'],\n",
       "        num_rows: 900384\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'tokens', 'ner_tags_str_mapped'],\n",
       "        num_rows: 112494\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'tokens', 'ner_tags_str_mapped'],\n",
       "        num_rows: 108378\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 3. Load Labeled FiNER-139 Dataset and Create DatasetDict\n",
    "train_path = \"./pipeline/data/finer-train.jsonl\" \n",
    "val_path = \"./pipeline/data/finer-validation.jsonl\"\n",
    "test_path = \"./pipeline/data/finer-test.jsonl\"\n",
    "\n",
    "# Expected format: {\"tokens\": [...], \"ner_tags_str_mapped\": [...]}\n",
    "train_data = Dataset.from_json(train_path)\n",
    "val_data = Dataset.from_json(val_path)\n",
    "test_data = Dataset.from_json(test_path)\n",
    "\n",
    "dataset = DatasetDict({\n",
    "    \"train\": train_data,\n",
    "    \"validation\": val_data,\n",
    "    \"test\": test_data\n",
    "})\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3420c3e0-0234-423c-bf36-88eed2218a62",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px; width:100%; background-color:black; border:none; margin:auto;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728fe499-f94f-4195-8ed6-c7b844f6bc1b",
   "metadata": {},
   "source": [
    "## 3. Label Mapping Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d166c50-5ab7-477f-b8e2-7ca0be36769a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_labels:  19\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['B-Acquisition',\n",
       " 'B-Assets',\n",
       " 'B-Compensation',\n",
       " 'B-Contingency',\n",
       " 'B-Debt',\n",
       " 'B-Equity',\n",
       " 'B-Lease',\n",
       " 'B-Other',\n",
       " 'B-Revenue',\n",
       " 'B-Tax',\n",
       " 'I-Acquisition',\n",
       " 'I-Assets',\n",
       " 'I-Compensation',\n",
       " 'I-Contingency',\n",
       " 'I-Debt',\n",
       " 'I-Equity',\n",
       " 'I-Lease',\n",
       " 'I-Other',\n",
       " 'O']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract all labels\n",
    "all_labels = set()\n",
    "for split in [\"train\", \"validation\", \"test\"]:\n",
    "    for ex in dataset[split][\"ner_tags_str_mapped\"]:\n",
    "        all_labels.update(ex)\n",
    "\n",
    "label_list = sorted(all_labels)\n",
    "label_to_id = {label: i for i, label in enumerate(label_list)}\n",
    "id_to_label = {i: label for label, i in label_to_id.items()}\n",
    "num_labels = len(label_list)\n",
    "print(\"num_labels: \", num_labels)\n",
    "label_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b96d065a-1171-4a5c-9cc6-37e1e01229a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label → ID mapping:\n",
      "{'B-Acquisition': 0, 'B-Assets': 1, 'B-Compensation': 2, 'B-Contingency': 3, 'B-Debt': 4, 'B-Equity': 5, 'B-Lease': 6, 'B-Other': 7, 'B-Revenue': 8, 'B-Tax': 9, 'I-Acquisition': 10, 'I-Assets': 11, 'I-Compensation': 12, 'I-Contingency': 13, 'I-Debt': 14, 'I-Equity': 15, 'I-Lease': 16, 'I-Other': 17, 'O': 18}\n",
      "\n",
      "ID → Label mapping:\n",
      "{0: 'B-Acquisition', 1: 'B-Assets', 2: 'B-Compensation', 3: 'B-Contingency', 4: 'B-Debt', 5: 'B-Equity', 6: 'B-Lease', 7: 'B-Other', 8: 'B-Revenue', 9: 'B-Tax', 10: 'I-Acquisition', 11: 'I-Assets', 12: 'I-Compensation', 13: 'I-Contingency', 14: 'I-Debt', 15: 'I-Equity', 16: 'I-Lease', 17: 'I-Other', 18: 'O'}\n",
      "\n",
      "Anzahl Labels: 19\n"
     ]
    }
   ],
   "source": [
    "## 3. Mapping format\n",
    "print(\"Label → ID mapping:\")\n",
    "print(label_to_id)\n",
    "\n",
    "print(\"\\nID → Label mapping:\")\n",
    "print(id_to_label)\n",
    "\n",
    "print(f\"\\nAnzahl Labels: {len(label_list)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04420b60-e44f-4490-a0b4-1ce3639c6827",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px; width:100%; background-color:black; border:none; margin:auto;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a027ad0-9e2d-4856-b174-da9207e31d69",
   "metadata": {},
   "source": [
    "## 4. Tokenization with Label Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "161d2c06-02fc-4e9f-b570-fe41e835252a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9542940eefe747d09d56a0fe83df3a97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=5):   0%|          | 0/108378 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Copied from production fine-tuning-script\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"./pipeline/bert-tapt\")  # shared tokenizer\n",
    "\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"tokens\"],\n",
    "        truncation=True,\n",
    "        is_split_into_words=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=512\n",
    "    )\n",
    "    \n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[\"ner_tags_str_mapped\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        label_ids = []\n",
    "        previous_word_idx = None\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label_to_id[label[word_idx]])\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n",
    "    \n",
    "tokenized_test = (dataset[\"test\"].map(tokenize_and_align_labels, batched=True, num_proc=5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1814be-5386-4e71-8e7c-0c3a49a1fd48",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px; width:100%; background-color:black; border:none; margin:auto;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41debbb8-08e8-419b-a504-4cde18d34f25",
   "metadata": {},
   "source": [
    "## 5. Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b368f8c5-8db9-4b9e-ace1-dd7ad613fe2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "metric = evaluate.load(\"seqeval\")\n",
    "\n",
    "label_to_id = {v: k for k, v in id_to_label.items()}\n",
    "O_ID = label_to_id.get(\"O\", None)\n",
    "\n",
    "def compute_metrics(p):\n",
    "    logits, labels = p\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "\n",
    "    # IDs -> tags, mask out -100 (subword labels)\n",
    "    true_labels = [[id_to_label[l] for l in lab if l != -100] for lab in labels]\n",
    "    true_preds  = [[id_to_label[p] for p, l in zip(pr, lab) if l != -100]\n",
    "                   for pr, lab in zip(preds, labels)]\n",
    "\n",
    "    # Span-level (entity-level) scores via seqeval (micro)\n",
    "    res = metric.compute(predictions=true_preds, references=true_labels)\n",
    "\n",
    "    out = {\n",
    "        \"precision\": res[\"overall_precision\"],\n",
    "        \"recall\":    res[\"overall_recall\"],\n",
    "        \"f1\":        res[\"overall_f1\"],\n",
    "        \"accuracy\":  res[\"overall_accuracy\"],\n",
    "    }\n",
    "\n",
    "    # Per-entity type (flatten so Trainer/logger like the keys)\n",
    "    per_type = {k: v for k, v in res.items() if not k.startswith(\"overall_\")}\n",
    "    for ent, m in per_type.items():\n",
    "        out[f\"type-{ent}_precision\"] = m[\"precision\"]\n",
    "        out[f\"type-{ent}_recall\"]    = m[\"recall\"]\n",
    "        out[f\"type-{ent}_f1\"]        = m[\"f1\"]\n",
    "        out[f\"type-{ent}_support\"]   = m[\"number\"]  # Anzahl wahrer Entitäten\n",
    "\n",
    "    # Macro and weighted-macro across entity types\n",
    "    if per_type:\n",
    "        supports = np.array([m[\"number\"] for m in per_type.values()], dtype=float)\n",
    "        weights  = supports / supports.sum() if supports.sum() > 0 else np.ones_like(supports)/len(supports)\n",
    "\n",
    "        precs = np.array([m[\"precision\"] for m in per_type.values()], dtype=float)\n",
    "        recs  = np.array([m[\"recall\"]    for m in per_type.values()], dtype=float)\n",
    "        f1s   = np.array([m[\"f1\"]        for m in per_type.values()], dtype=float)\n",
    "\n",
    "        out[\"precision_macro\"]  = float(np.nanmean(precs))\n",
    "        out[\"recall_macro\"]     = float(np.nanmean(recs))\n",
    "        out[\"f1_macro\"]         = float(np.nanmean(f1s))\n",
    "\n",
    "        out[\"precision_weighted\"] = float(np.nansum(precs * weights))\n",
    "        out[\"recall_weighted\"]    = float(np.nansum(recs  * weights))\n",
    "        out[\"f1_weighted\"]        = float(np.nansum(f1s   * weights))\n",
    "\n",
    "    # Token accuracy (including and excluding 'O'); still mask -100\n",
    "    mask = (labels != -100)\n",
    "    correct = (preds == labels) & mask\n",
    "    token_acc = correct.sum() / mask.sum()\n",
    "    out[\"token_acc\"] = float(token_acc)\n",
    "\n",
    "    if O_ID is not None:\n",
    "        mask_wo_O = mask & (labels != O_ID)\n",
    "        if mask_wo_O.sum() > 0:\n",
    "            correct_wo_O = (preds == labels) & mask_wo_O\n",
    "            out[\"token_acc_wo_O\"] = float(correct_wo_O.sum() / mask_wo_O.sum())\n",
    "        else:\n",
    "            out[\"token_acc_wo_O\"] = float(\"nan\")\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb34cc3-640d-43d3-a137-3c2ca3bcec86",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px; width:100%; background-color:black; border:none; margin:auto;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5f1560-83b7-42c5-b468-ec6971d2d17a",
   "metadata": {},
   "source": [
    "## 6. Data Collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78730b34-958f-4309-a505-05f7e80238b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForTokenClassification(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d21db0-8934-4c39-8069-55e526a120f1",
   "metadata": {},
   "source": [
    "# 7. Evaluate Both Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "457a6b16-8e16-44d1-b6cc-545ec56419da",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_args = TrainingArguments(\n",
    "    per_device_eval_batch_size=64,\n",
    "    dataloader_num_workers=24,\n",
    "    dataloader_pin_memory=True,\n",
    "    bf16=True,\n",
    "    report_to=\"none\",\n",
    "    seed=42,\n",
    "    data_seed=42,                           \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cd47ee-eb68-4674-9f33-065bc3958643",
   "metadata": {},
   "source": [
    "# 🔵 Evaluate bert-finetuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14334e43-dd2a-4c00-a4f1-05fbf62c9abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_33347/3085200126.py:3: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer_base = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Base Model F1: 0.8502\n"
     ]
    }
   ],
   "source": [
    "model_base = BertForTokenClassification.from_pretrained(\"./pipeline/bert-base-finetuned\").to(device)\n",
    "\n",
    "trainer_base = Trainer(\n",
    "    model=model_base,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    args=eval_args\n",
    ")\n",
    "\n",
    "output_base = trainer_base.predict(tokenized_test.remove_columns([\"tokens\", \"ner_tags_str_mapped\"]))\n",
    "f1_base, metrics_base = compute_metrics((output_base.predictions, output_base.label_ids))\n",
    "\n",
    "print(f\"📊 Base Model F1: {f1_base:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fdc184-3a25-403e-a55d-d942986a4ad7",
   "metadata": {},
   "source": [
    "# 🟢 Evaluate bert-tapt-finetuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58a03ce7-8624-4a33-ae48-44e1020fad16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_33347/56299418.py:3: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer_tapt = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📈 TAPT Model F1: 0.8596\n"
     ]
    }
   ],
   "source": [
    "model_tapt = BertForTokenClassification.from_pretrained(\"./pipeline/bert-tapt-finetuned\").to(device)\n",
    "\n",
    "trainer_tapt = Trainer(\n",
    "    model=model_tapt,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    args=eval_args\n",
    ")\n",
    "\n",
    "output_tapt = trainer_tapt.predict(tokenized_test.remove_columns([\"tokens\", \"ner_tags_str_mapped\"]))\n",
    "f1_tapt, metrics_tapt = compute_metrics((output_tapt.predictions, output_tapt.label_ids))\n",
    "\n",
    "print(f\"📈 TAPT Model F1: {f1_tapt:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586b9400-71aa-47db-8166-89a1f56cea56",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px; width:100%; background-color:black; border:none; margin:auto;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714cd669-6172-4ae3-84a2-a20f180acd14",
   "metadata": {},
   "source": [
    "# 8. Analysing Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fdb7a542-0d3d-4c7d-828e-ae05590f0214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>token_acc</th>\n",
       "      <th>token_acc_wo_O</th>\n",
       "      <th>precision_macro</th>\n",
       "      <th>recall_macro</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>precision_weighted</th>\n",
       "      <th>recall_weighted</th>\n",
       "      <th>f1_weighted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Base</th>\n",
       "      <td>0.8116</td>\n",
       "      <td>0.8928</td>\n",
       "      <td>0.8502</td>\n",
       "      <td>0.9981</td>\n",
       "      <td>0.9981</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.8142</td>\n",
       "      <td>0.8853</td>\n",
       "      <td>0.8482</td>\n",
       "      <td>0.8117</td>\n",
       "      <td>0.8928</td>\n",
       "      <td>0.8502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAPT</th>\n",
       "      <td>0.8223</td>\n",
       "      <td>0.9004</td>\n",
       "      <td>0.8596</td>\n",
       "      <td>0.9982</td>\n",
       "      <td>0.9982</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>0.8931</td>\n",
       "      <td>0.8582</td>\n",
       "      <td>0.8226</td>\n",
       "      <td>0.9004</td>\n",
       "      <td>0.8596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       precision  recall      f1  accuracy  token_acc  token_acc_wo_O  \\\n",
       "model                                                                   \n",
       "Base      0.8116  0.8928  0.8502    0.9981     0.9981           0.887   \n",
       "TAPT      0.8223  0.9004  0.8596    0.9982     0.9982           0.895   \n",
       "\n",
       "       precision_macro  recall_macro  f1_macro  precision_weighted  \\\n",
       "model                                                                \n",
       "Base            0.8142        0.8853    0.8482              0.8117   \n",
       "TAPT            0.8262        0.8931    0.8582              0.8226   \n",
       "\n",
       "       recall_weighted  f1_weighted  \n",
       "model                                \n",
       "Base            0.8928       0.8502  \n",
       "TAPT            0.9004       0.8596  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>entity</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Base</td>\n",
       "      <td>Acquisition</td>\n",
       "      <td>0.7821</td>\n",
       "      <td>0.8531</td>\n",
       "      <td>0.8160</td>\n",
       "      <td>1851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TAPT</td>\n",
       "      <td>Acquisition</td>\n",
       "      <td>0.7731</td>\n",
       "      <td>0.8504</td>\n",
       "      <td>0.8099</td>\n",
       "      <td>1851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Base</td>\n",
       "      <td>Assets</td>\n",
       "      <td>0.8088</td>\n",
       "      <td>0.9008</td>\n",
       "      <td>0.8523</td>\n",
       "      <td>2691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TAPT</td>\n",
       "      <td>Assets</td>\n",
       "      <td>0.8216</td>\n",
       "      <td>0.9090</td>\n",
       "      <td>0.8631</td>\n",
       "      <td>2691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Base</td>\n",
       "      <td>Compensation</td>\n",
       "      <td>0.8419</td>\n",
       "      <td>0.9237</td>\n",
       "      <td>0.8809</td>\n",
       "      <td>4405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TAPT</td>\n",
       "      <td>Compensation</td>\n",
       "      <td>0.8508</td>\n",
       "      <td>0.9330</td>\n",
       "      <td>0.8900</td>\n",
       "      <td>4405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Base</td>\n",
       "      <td>Contingency</td>\n",
       "      <td>0.8122</td>\n",
       "      <td>0.8577</td>\n",
       "      <td>0.8343</td>\n",
       "      <td>1729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TAPT</td>\n",
       "      <td>Contingency</td>\n",
       "      <td>0.8306</td>\n",
       "      <td>0.8647</td>\n",
       "      <td>0.8473</td>\n",
       "      <td>1729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Base</td>\n",
       "      <td>Debt</td>\n",
       "      <td>0.7988</td>\n",
       "      <td>0.9017</td>\n",
       "      <td>0.8471</td>\n",
       "      <td>10394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TAPT</td>\n",
       "      <td>Debt</td>\n",
       "      <td>0.8095</td>\n",
       "      <td>0.9085</td>\n",
       "      <td>0.8562</td>\n",
       "      <td>10394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Base</td>\n",
       "      <td>Equity</td>\n",
       "      <td>0.8159</td>\n",
       "      <td>0.8734</td>\n",
       "      <td>0.8437</td>\n",
       "      <td>3522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TAPT</td>\n",
       "      <td>Equity</td>\n",
       "      <td>0.8247</td>\n",
       "      <td>0.8805</td>\n",
       "      <td>0.8517</td>\n",
       "      <td>3522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Base</td>\n",
       "      <td>Lease</td>\n",
       "      <td>0.8082</td>\n",
       "      <td>0.8755</td>\n",
       "      <td>0.8405</td>\n",
       "      <td>1333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>TAPT</td>\n",
       "      <td>Lease</td>\n",
       "      <td>0.8276</td>\n",
       "      <td>0.8785</td>\n",
       "      <td>0.8523</td>\n",
       "      <td>1333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Base</td>\n",
       "      <td>Other</td>\n",
       "      <td>0.7923</td>\n",
       "      <td>0.8599</td>\n",
       "      <td>0.8247</td>\n",
       "      <td>1699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>TAPT</td>\n",
       "      <td>Other</td>\n",
       "      <td>0.8015</td>\n",
       "      <td>0.8840</td>\n",
       "      <td>0.8408</td>\n",
       "      <td>1699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Base</td>\n",
       "      <td>Revenue</td>\n",
       "      <td>0.8443</td>\n",
       "      <td>0.9039</td>\n",
       "      <td>0.8731</td>\n",
       "      <td>1446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>TAPT</td>\n",
       "      <td>Revenue</td>\n",
       "      <td>0.8693</td>\n",
       "      <td>0.9108</td>\n",
       "      <td>0.8896</td>\n",
       "      <td>1446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Base</td>\n",
       "      <td>Tax</td>\n",
       "      <td>0.8378</td>\n",
       "      <td>0.9029</td>\n",
       "      <td>0.8691</td>\n",
       "      <td>1504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>TAPT</td>\n",
       "      <td>Tax</td>\n",
       "      <td>0.8531</td>\n",
       "      <td>0.9116</td>\n",
       "      <td>0.8814</td>\n",
       "      <td>1504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model        entity  precision  recall      f1  support\n",
       "0   Base   Acquisition     0.7821  0.8531  0.8160     1851\n",
       "1   TAPT   Acquisition     0.7731  0.8504  0.8099     1851\n",
       "2   Base        Assets     0.8088  0.9008  0.8523     2691\n",
       "3   TAPT        Assets     0.8216  0.9090  0.8631     2691\n",
       "4   Base  Compensation     0.8419  0.9237  0.8809     4405\n",
       "5   TAPT  Compensation     0.8508  0.9330  0.8900     4405\n",
       "6   Base   Contingency     0.8122  0.8577  0.8343     1729\n",
       "7   TAPT   Contingency     0.8306  0.8647  0.8473     1729\n",
       "8   Base          Debt     0.7988  0.9017  0.8471    10394\n",
       "9   TAPT          Debt     0.8095  0.9085  0.8562    10394\n",
       "10  Base        Equity     0.8159  0.8734  0.8437     3522\n",
       "11  TAPT        Equity     0.8247  0.8805  0.8517     3522\n",
       "12  Base         Lease     0.8082  0.8755  0.8405     1333\n",
       "13  TAPT         Lease     0.8276  0.8785  0.8523     1333\n",
       "14  Base         Other     0.7923  0.8599  0.8247     1699\n",
       "15  TAPT         Other     0.8015  0.8840  0.8408     1699\n",
       "16  Base       Revenue     0.8443  0.9039  0.8731     1446\n",
       "17  TAPT       Revenue     0.8693  0.9108  0.8896     1446\n",
       "18  Base           Tax     0.8378  0.9029  0.8691     1504\n",
       "19  TAPT           Tax     0.8531  0.9116  0.8814     1504"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "# 1) Compute metrics from finished prediction outputs\n",
    "metrics_base = compute_metrics((output_base.predictions, output_base.label_ids))\n",
    "metrics_tapt  = compute_metrics((output_tapt.predictions,  output_tapt.label_ids))\n",
    "\n",
    "results = {\"Base\": metrics_base, \"TAPT\": metrics_tapt}\n",
    "\n",
    "# 2) Build summary table (overall/macro/weighted/token metrics; excludes per-type keys)\n",
    "def make_summary_df(results):\n",
    "    rows = []\n",
    "    for name, m in results.items():\n",
    "        row = {k: v for k, v in m.items() if not k.startswith(\"type-\")}\n",
    "        row[\"model\"] = name\n",
    "        rows.append(row)\n",
    "    df = pd.DataFrame(rows).set_index(\"model\")\n",
    "\n",
    "    wanted = [\n",
    "        \"precision\",\"recall\",\"f1\",\"accuracy\",\n",
    "        \"token_acc\",\"token_acc_wo_O\",\n",
    "        \"precision_macro\",\"recall_macro\",\"f1_macro\",\n",
    "        \"precision_weighted\",\"recall_weighted\",\"f1_weighted\",\n",
    "    ]\n",
    "    cols = [c for c in wanted if c in df.columns] + [c for c in df.columns if c not in wanted]\n",
    "    return df[cols]\n",
    "\n",
    "summary_df = make_summary_df(results)\n",
    "\n",
    "# 3) Build per-entity table (precision/recall/F1/support per entity type)\n",
    "def make_per_type_df(results):\n",
    "    rows = []\n",
    "    for name, m in results.items():\n",
    "        ents = sorted({k.split(\"_\", 1)[0].replace(\"type-\",\"\") for k in m if k.startswith(\"type-\")})\n",
    "        for ent in ents:\n",
    "            rows.append({\n",
    "                \"model\": name,\n",
    "                \"entity\": ent,\n",
    "                \"precision\": m.get(f\"type-{ent}_precision\", float(\"nan\")),\n",
    "                \"recall\":    m.get(f\"type-{ent}_recall\",    float(\"nan\")),\n",
    "                \"f1\":        m.get(f\"type-{ent}_f1\",        float(\"nan\")),\n",
    "                \"support\":   m.get(f\"type-{ent}_support\",   float(\"nan\")),\n",
    "            })\n",
    "    return pd.DataFrame(rows).sort_values([\"entity\",\"model\"]).reset_index(drop=True)\n",
    "\n",
    "per_type_df = make_per_type_df(results)\n",
    "\n",
    "# 4) Display (rounded)\n",
    "display(summary_df.round(4).rename_axis(\"model\"))\n",
    "display(per_type_df.round(4))\n",
    "\n",
    "# Optional: CSV export\n",
    "# summary_df.round(6).to_csv(\"ner_metrics_summary.csv\")\n",
    "# per_type_df.round(6).to_csv(\"ner_metrics_per_type.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3a9a46-5934-43b3-b286-58365d2e3f0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
